self$hidden1 <- nn_linear(p, q1)
self$hidden2 <- nn_linear(q1, q2)
self$hidden3 <- nn_linear(q2, q3)
self$output <- nn_linear(q3,1)
self$activation <- nn_relu()
self$sigmoid <- nn_sigmoid()
},
forward = function(x){
x %>%
self$hidden1() %>%
self$activation() %>%
self$hidden2()
self$activation() %>%
self$hidden3() %>%
self$activation() %>%
self$output() %>%
self$sigmoid()
}
)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
M2 <- model.matrix(median_house_value ~ 0 + . -households, data = df_test)
nnet_fit <- NNet %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_binary_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
M,
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
M2,
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
NNet <- nn_module(
initialize = function(p, q1, q2, q3){
self$hidden1 <- nn_linear(p, q1)
self$hidden2 <- nn_linear(q1, q2)
self$hidden3 <- nn_linear(q2, q3)
self$output <- nn_linear(q3,1)
self$activation <- nn_relu()
self$sigmoid <- nn_sigmoid()
},
forward = function(x){
x %>%
self$hidden1() %>%
self$activation() %>%
self$hidden2()
self$activation() %>%
self$hidden3() %>%
self$activation() %>%
self$output() #%>%
#self$sigmoid()
}
)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
M2 <- model.matrix(median_house_value ~ 0 + . -households, data = df_test)
nnet_fit <- NNet %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_binary_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
M,
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
M2,
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
M
M2
ncol(M)
M <- model.matrix(median_house_value ~ 0 + . -households, data = df_train)
M2 <- model.matrix(median_house_value ~ 0 + . -households, data = df_test)
nnet_fit <- NNet %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_binary_accuracy()
)
) %>%
set_hparams(
p = ncol(df), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
M,
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
M2,
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_binary_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
M,
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
M2,
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_binary_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
nnet_fit <- NNet %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam,
metrics = list(
luz_metric_binary_accuracy()
)
) %>%
set_hparams(
p = ncol(M), q1 = 32, q2 = 16, q3 = 8
) %>%
set_opt_hparams(
lr = 0.01
) %>%
fit(
data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_train),
df_train %>% select(median_house_value) %>% as.matrix
),
valid_data = list(
model.matrix(median_house_value ~ 0 + . -households, data = df_test),
df_test %>% select(median_house_value) %>% as.matrix
),
epochs = 50,
#dataloader_options = list(num_workers = 0),
verbose = TRUE # Change to TRUE while tuning. But, set to FALSE before submitting
)
rmse(df_test$median_house_value, predict(svm_fit, newdata = df_test))
rpart_RMSE <- rmse(df_test$median_house_value, rpart_predictions)
rpart_RMSE
rpart_fit <- rpart(median_house_value ~ . -households, data = df_train)
rpart_predictions <- predict(rpart_fit, newdata = df_test)
rpart.plot(rpart_fit, tweak = 0.8)
rpart_RMSE <- rmse(df_test$median_house_value, rpart_predictions)
rpart_RMSE
rmse <- function(y, yhat) {
sqrt(mean((y - yhat)^2))
}
lm_predictions <- predict(lm_fit, newdata = df_test)
lm_RMSE <- rmse(df_test$median_house_value, lm_predictions)
lm_RMSE
summary_table <- rbind(lm_RMSE, rpart_RMSE, svm_RMSE) %>%
mutate(Model = c('Linear Regression', 'Decision Tree', 'SVM', 'Neural Network'))
svm_fit <- svm(median_house_value ~ . -households, data = df_train, kernel = 'radial')
svm_predictions <- predict(svm_fit, newdata = df_test)
svm_RMSE <- rmse(df_test$median_house_value, svm_predictions)
svm_RMSE
summary_table <- rbind(lm_RMSE, rpart_RMSE, svm_RMSE) %>%
mutate(Model = c('Linear Regression', 'Decision Tree', 'SVM', 'Neural Network'))
summary_table <- rbind(lm_RMSE, rpart_RMSE, svm_RMSE)
summary_table
summary_table <- data.frame(rbind(lm_RMSE, rpart_RMSE, svm_RMSE))
summary_table
summary_table %>%
mutate(df[,1] = c('Linear Regression', 'Decision Tree', 'SVM', 'Neural Network'))
str(lm_RMSE)
summary_table <- data.frame(
Model = c('Linear Regression', 'Decision Tree', 'SVM', 'Neural Network'),
RMSE = c(lm_RMSE, rpart_RMSE, svm_RMSE)
)
summary_table <- data.frame(
Model = c('Linear Regression', 'Decision Tree', 'SVM'),
RMSE = c(lm_RMSE, rpart_RMSE, svm_RMSE)
)
summary_table
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM'))
summary <- cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM')) %>%
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows()
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows()
summary <- list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM'))
summary <- list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM'))
summary
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows()
summary <- list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows()
summary
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM'))
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM')) %>%
select (Model, accuracy, error, true_positive_rate, false_positive_rate)
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM')) %>%
select (Model, accuracy, error, true_positive_rate, false_positive_rate) %>%
knitr::kable()
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM')) %>%
select (Model, accuracy, error, true_positive_rate, false_positive_rate)
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM')) %>%
select (Model, accuracy, error, true_positive_rate, false_positive_rate)
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM'))
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows()
rpart_classes <- rpart(spam ~ ., data = df2_train, method = 'class')
rpart.plot(rpart_classes)
rpart_classes <- ifelse(predict(rpart_classes, newdata = df2_test) > 0.5, 1, 0) %>% as.factor
overview(rpart_classes, df2_test$spam)
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows()
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%>
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = 'Logistic Regression', 'Decision Tree', 'SVM')
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = 'Logistic Regression', 'Decision Tree', 'SVM') %>%
select(Model, accuracy, error, true_positive_rate, false_positive_rate)
list(glm_classes, rpart_classes, svm_classes) %>%
lapply(\(x) overview(x, df2_test$spam)) %>%
bind_rows() %>%
cbind(Model = c('Logistic Regression', 'Decision Tree', 'SVM')) %>%
select(Model, accuracy, error, true_positive_rate, false_positive_rate)
df <- generate_three_spirals()
plot(
df$x1, df$x2,
col = df$y,
pch = 20
)
grid <- expand.grid(x1 = seq(-10, 10, length.out = 100), x2 = seq(-10, 10, length.out = 100))
df_test <- tibble(grid)
grid <- expand.grid(x1 = seq(-10, 10, length.out = 10), x2 = seq(-10, 10, length.out = 10))
df_test <- tibble(grid)
df_test
generate_three_spirals <- function(){
set.seed(42)
n <- 500
noise <- 0.2
t <- (1:n) / n * 2 * pi
x1 <- c(
t * (sin(t) + rnorm(n, 0, noise)),
t * (sin(t + 2 * pi/3) + rnorm(n, 0, noise)),
t * (sin(t + 4 * pi/3) + rnorm(n, 0, noise))
)
x2 <- c(
t * (cos(t) + rnorm(n, 0, noise)),
t * (cos(t + 2 * pi/3) + rnorm(n, 0, noise)),
t * (cos(t + 4 * pi/3) + rnorm(n, 0, noise))
)
y <- as.factor(
c(
rep(0, n),
rep(1, n),
rep(2, n)
)
)
return(tibble(x1=x1, x2=x2, y=y))
}
df <- generate_three_spirals()
plot(
df$x1, df$x2,
col = df$y,
pch = 20
)
grid <- expand.grid(x1 = seq(-10, 10, length.out = 10), x2 = seq(-10, 10, length.out = 10))
df_test <- tibble(grid)
df_test
rpart_fit <- rpart(y ~ df$x1 + df$x2, data = df)
rpart_classes <- predict(rpart_fit, df$y)
rpart_fit <- rpart(y ~ df$x1 + df$x2, data = df)
rpart_classes <- predict(rpart_fit, df_test$y)
rpart_classes <- predict(rpart_fit, df$y)
rpart_classes
rpart_fit <- rpart(y ~ df$x1 + df$x2, data = df)
rpart_classes <- predict(rpart_fit, df$y)
plot_decision_boundary <- function(predictions){
plot(
df_test$x1, df_test$x2,
col = predictions,
pch = 0
)
points(
df$x1, df$x2,
col = df$y,
pch = 20
)
}
plot_decision_boundary(rpart_classes)
svm_fit <- svm(y ~ x1 + x2 , data = df, type = 'C-classification')
svm_classes <- predict(svm_fit, newdata = df_test)
plot_decision_boundary(svm_classes)
NN1 <- nn_module(
initialize = function(p, q1, o){
self$hidden1 <- nn_linear(p, q1)
self$output <- nn_linear(q1, o)
self$activation <- nn_relu()
},
forward = function(x){
x %>%
self$hidden1() %>%
self$activation() %>%
self$output()
}
)
fit_1 <- NN1 %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam
) %>%
set_hparams(
p = 10, q1 = 10, o =3
) %>%
set_opt_params(
lr = 0.005
) %>%
fit(
data = list(
df %>% select(x1, x2) %>% as.matrix,
df$y %>% as.integer
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = FALSE
)
fit_1 <- NN1 %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam
) %>%
set_hparams(
p = 10, q1 = 10, o =3
) %>%
set_opt_hparams(
lr = 0.005
) %>%
fit(
data = list(
df %>% select(x1, x2) %>% as.matrix,
df$y %>% as.integer
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = FALSE
)
fit_1 <- NN1 %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam
) %>%
set_hparams(
p = 2, q1 = 10, o =3
) %>%
set_opt_hparams(
lr = 0.005
) %>%
fit(
data = list(
df %>% select(x1, x2) %>% as.matrix,
df$y %>% as.integer
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = FALSE
)
fit_1 <- NN1 %>%
setup(
loss = nn_mse_loss(),
optimizer = optim_adam
) %>%
set_hparams(
p = ncol(df), q1 = 10, o =3
) %>%
set_opt_hparams(
lr = 0.005
) %>%
fit(
data = list(
df %>% select(x1, x2) %>% as.matrix,
df$y %>% as.integer
),
epochs = 50,
dataloader_options = list(num_workers = 0),
verbose = FALSE
)
packages <- c(
"dplyr",
"readr",
"tidyr",
"purrr",
"broom",
"magrittr",
"corrplot",
"caret",
"rpart",
"rpart.plot",
"e1071",
"torch",
"luz"
)
renv::install(packages)
sapply(packages, require, character.only=T)
install.packages('torch')
library(torch)
